{
    "dataset_reader": {
        "type": "syntactic_dependency_arc_prediction",
        "contextualizer": {
            "type": "precomputed_contextualizer",
            "representations_path": "contextualizers/bert_base_cased/ptb_syntactic_dependency.hdf5"
        },
        "negative_sampling_method": "balanced",
        # This saves memory and speeds up the model if we don't need access to the tokens in the model.
        "include_raw_tokens": false
    },
    "validation_dataset_reader": {
        "type": "syntactic_dependency_arc_prediction",
        "contextualizer": {
            "type": "precomputed_contextualizer",
            "representations_path": "contextualizers/bert_base_cased/ptb_syntactic_dependency.hdf5"
        },
        "negative_sampling_method": "balanced",
        # This saves memory and speeds up the model if we don't need access to the tokens in the model.
        "include_raw_tokens": false
    },
    "train_data_path": "data/syntactic_dependency/ptb.train.conllu",
    "validation_data_path": "data/syntactic_dependency/ptb.dev.conllu",
    "test_data_path": "data/syntactic_dependency/ptb.test.conllu",
    "evaluate_on_test" : true,
    "model": {
        "type": "pairwise_tagger",
        "token_representation_dim": 768,
        "combination": "x,y,x*y"
    },
    "iterator": {
        "type": "basic",
        "batch_size" : 80
    },
    "trainer": {
        "num_epochs": 50,
        "patience": 3,
        "cuda_device": 0,
        "validation_metric": "+accuracy",
        "optimizer": {
            "type": "adam",
            "lr": 0.001
        }
    }
}
